chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
  if (request.action === 'extractTranscript') {
    try {
      const transcriptPanel = document.querySelector('ytd-transcript-renderer');
      if (!transcriptPanel) {
        sendResponse({ transcript: null });
        return;
      }
      const transcriptElements = document.querySelectorAll('ytd-transcript-segment-renderer .segment-text');
      if (transcriptElements.length === 0) {
        sendResponse({ transcript: null });
        return;
      }
      // Extract video ID from URL
      const urlParams = new URLSearchParams(window.location.search);
      const videoId = urlParams.get('v') || 'unknown';
      
      // Format transcript with timestamps
      const transcriptLines = Array.from(transcriptElements)
        .map((el, index) => {
          const timestampEl = el.closest('ytd-transcript-segment-renderer').querySelector('.segment-timestamp');
          const timeText = timestampEl ? timestampEl.textContent.trim() : `00:00:${index.toString().padStart(2, '0')}`;
          return `[${timeText}] ${el.textContent.trim()}`;
        });
      
      // Prepend instructional header
      const header = `Transcript of a YouTube Video (ID: ${videoId})
Generated by the "YouTube Transcript and Screenshot Extractor" Chrome Extension

This transcript contains the spoken content of a YouTube video, with timestamps in [MM:SS] format (e.g., [0:10]) indicating the time each segment begins. Screenshots for multiple timestamps, including Â±5s offsets, are bundled into a single PDF file named "screenshots.pdf". Each screenshot in the PDF is labeled with its timestamp and offset (e.g., "Screenshot at 0:10 (0s)"). You can request a screenshot at a specific timestamp by saying, for example, "Please provide the screenshot at [0:10]." The user will upload the PDF containing the screenshots, and you can refer to the labeled screenshot in the PDF for further analysis.

Transcript Content:
`;
      
      // Combine header and transcript
      const transcript = header + transcriptLines.join('\n');
      sendResponse({ transcript });
    } catch (e) {
      sendResponse({ transcript: null });
    }
  } else if (request.action === 'captureScreenshot') {
    try {
      const video = document.querySelector('video');
      if (!video || video.paused || video.currentTime === 0) {
        sendResponse({ screenshot: null });
        return;
      }
      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      const dataUrl = canvas.toDataURL('image/png');
      sendResponse({ screenshot: dataUrl });
    } catch (e) {
      sendResponse({ screenshot: null });
    }
  } else if (request.action === 'captureAtTime') {
    try {
      const video = document.querySelector('video');
      if (!video) {
        sendResponse({ screenshot: null });
        return;
      }
      video.currentTime = request.time;
      const onSeeked = () => {
        const canvas = document.createElement('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        canvas.getContext('2d').drawImage(video, 0, 0);
        const dataUrl = canvas.toDataURL('image/png');
        sendResponse({ screenshot: dataUrl });
        video.removeEventListener('seeked', onSeeked);
      };
      video.addEventListener('seeked', onSeeked);
      return true; // Indicates async response
    } catch (e) {
      sendResponse({ screenshot: null });
    }
  }
});